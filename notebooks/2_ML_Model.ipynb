{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# üß† Mod√©lisation Pr√©dictive - Performance Commerciale\n",
    "\n",
    "**Objectifs** :\n",
    "1. Pr√©dire la probabilit√© de conversion par appel\n",
    "2. Identifier les drivers cl√©s de performance\n",
    "3. G√©n√©rer des recommandations actionnables\n",
    "\n",
    "**Approche** :\n",
    "- Random Forest (classification binaire)\n",
    "- Feature Importance + SHAP Values\n",
    "- Validation temporelle\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (classification_report, roc_auc_score,\n",
    "                             ConfusionMatrixDisplay, RocCurveDisplay)\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "import mlflow\n",
    "import joblib\n",
    "\n",
    "# Configuration globale\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"husl\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Chargement des Donn√©es\n",
    "# %%\n",
    "DATA_PATH = \"../data/generated/campaign_data.csv\"\n",
    "\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Charge et pr√©pare les donn√©es brutes\"\"\"\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        parse_dates=['call_date'],\n",
    "        dtype={\n",
    "            'region': 'category',\n",
    "            'product': 'category',\n",
    "            'script_version': 'category'\n",
    "        }\n",
    "    )\n",
    "    df['converted'] = df['converted'].astype('bool')\n",
    "    df['call_hour'] = df['call_time'].astype('category')\n",
    "    return df.sort_values('call_date')\n",
    "\n",
    "df = load_data(DATA_PATH)\n",
    "print(f\"üìä Dimensions initiales : {df.shape}\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Feature Engineering\n",
    "# %%\n",
    "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Cr√©e des features m√©tier et temporelles\"\"\"\n",
    "    # Features temporelles\n",
    "    df['day_of_week'] = df['call_date'].dt.day_name()\n",
    "    df['is_weekend'] = df['call_date'].dt.weekday >= 5\n",
    "    \n",
    "    # Features m√©tier\n",
    "    df['peak_hour'] = df['call_time'].between(14, 16)\n",
    "    df['duration_min'] = df['duration'] / 60\n",
    "    \n",
    "    # Interaction features\n",
    "    df['script_region'] = df['script_version'] + '_' + df['region']\n",
    "    return df\n",
    "\n",
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## 4. Pr√©paration des Donn√©es\n",
    "# %%\n",
    "TARGET = 'converted'\n",
    "FEATURES = [\n",
    "    'duration_min',\n",
    "    'peak_hour',\n",
    "    'region',\n",
    "    'product',\n",
    "    'script_version',\n",
    "    'day_of_week'\n",
    "]\n",
    "\n",
    "# Split temporel\n",
    "train_size = int(len(df) * 0.8)\n",
    "X_train, X_test = df[FEATURES].iloc[:train_size], df[FEATURES].iloc[train_size:]\n",
    "y_train, y_test = df[TARGET].iloc[:train_size], df[TARGET].iloc[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## 5. Pipeline de Pr√©processing\n",
    "# %%\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), ['duration_min']),\n",
    "    (OneHotEncoder(\n",
    "        handle_unknown='ignore',\n",
    "        drop='if_binary'\n",
    "    ), ['region', 'product', 'script_version', 'day_of_week']),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Get feature names\n",
    "preprocessor.fit(X_train)\n",
    "ohe = preprocessor.named_transformers_['onehotencoder']\n",
    "feature_names = (\n",
    "    ['duration_scaled'] + \n",
    "    list(ohe.get_feature_names_out()) + \n",
    "    ['peak_hour']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## 6. Entra√Ænement du Mod√®le\n",
    "# %%\n",
    "def train_model(X, y):\n",
    "    \"\"\"Pipeline complet d'entra√Ænement avec optimisation\"\"\"\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            early_stopping_rounds=10\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'classifier__max_depth': [3, 5],\n",
    "        'classifier__learning_rate': [0.05, 0.1],\n",
    "        'classifier__subsample': [0.8, 1.0]\n",
    "    }\n",
    "    \n",
    "    cv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        search = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid,\n",
    "            cv=cv,\n",
    "            scoring='roc_auc',\n",
    "            verbose=2\n",
    "        )\n",
    "        search.fit(X, y)\n",
    "        \n",
    "        # Logging MLflow\n",
    "        mlflow.log_params(search.best_params_)\n",
    "        mlflow.log_metric(\"best_auc\", search.best_score_)\n",
    "        mlflow.sklearn.log_model(search.best_estimator_, \"model\")\n",
    "        \n",
    "        return search.best_estimator_\n",
    "\n",
    "best_model = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## 7. √âvaluation\n",
    "# %%\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"√âvaluation compl√®te du mod√®le\"\"\"\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    print(classification_report(y, y_pred))\n",
    "    print(f\"\\nAUC Score: {roc_auc_score(y, y_proba):.2f}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    ConfusionMatrixDisplay.from_predictions(y, y_pred, ax=ax[0])\n",
    "    RocCurveDisplay.from_predictions(y, y_proba, ax=ax[1])\n",
    "    plt.tight_layout()\n",
    "\n",
    "print(\"üöÄ Performances sur le Test Set :\")\n",
    "evaluate_model(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## 8. Explicabilit√© avec SHAP\n",
    "# %%\n",
    "def explain_model(model, X):\n",
    "    \"\"\"Analyse d'impact des features avec SHAP\"\"\"\n",
    "    \n",
    "    # Pr√©paration des donn√©es\n",
    "    processed_data = model.named_steps['preprocessor'].transform(X)\n",
    "    explainer = shap.TreeExplainer(model.named_steps['classifier'])\n",
    "    \n",
    "    # Calcul des valeurs SHAP\n",
    "    shap_values = explainer.shap_values(processed_data)\n",
    "    \n",
    "    # Visualisation\n",
    "    fig1 = plt.figure()\n",
    "    shap.summary_plot(shap_values, processed_data, feature_names=feature_names)\n",
    "    \n",
    "    fig2 = plt.figure()\n",
    "    shap.dependence_plot(\n",
    "        'peak_hour',\n",
    "        shap_values,\n",
    "        processed_data,\n",
    "        feature_names=feature_names,\n",
    "        interaction_index=None\n",
    "    )\n",
    "    \n",
    "    return fig1, fig2\n",
    "\n",
    "print(\"üîç Interpr√©tabilit√© du mod√®le :\")\n",
    "explain_model(best_model, X_test.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## 9. D√©ploiement\n",
    "# %%\n",
    "def deploy_model(model, version: str = \"1.0.0\"):\n",
    "    \"\"\"Exporte le mod√®le pour la production\"\"\"\n",
    "    \n",
    "    # Sauvegarde locale\n",
    "    joblib.dump(model, f\"models/model_v{version}.pkl\")\n",
    "    \n",
    "    # Logging d'artefacts\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_artifact(\"feature_importance.png\")\n",
    "        mlflow.log_param(\"version\", version)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le version {version} d√©ploy√© avec succ√®s\")\n",
    "\n",
    "deploy_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## 10. Recommandations Strat√©giques\n",
    "# %%\n",
    "def generate_recommendations(model, features):\n",
    "    \"\"\"G√©n√®re des insights actionnables √† partir du mod√®le\"\"\"\n",
    "    \n",
    "    # Calcul des meilleures combinaisons\n",
    "    df_analysis = features.copy()\n",
    "    df_analysis['pred_proba'] = model.predict_proba(features)[:, 1]\n",
    "    \n",
    "    recommendations = (\n",
    "        df_analysis.groupby(['script_version', 'peak_hour', 'region'])\n",
    "        ['pred_proba'].mean()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(5)\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Formatage Markdown\n",
    "    md_output = \"## üéØ Top 5 des Strat√©gies Recommand√©es\\n\\n\"\n",
    "    for idx, row in recommendations.iterrows():\n",
    "        md_output += (\n",
    "            f\"{idx+1}. **Script {row['script_version']}** en **{row['region']}** \"\n",
    "            f\"entre **{14}h et {16}h** : \"\n",
    "            f\"Taux de conversion estim√© √† **{row['pred_proba']*100:.1f}%**\\n\\n\"\n",
    "        )\n",
    "    \n",
    "    return md_output\n",
    "\n",
    "print(generate_recommendations(best_model, X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
